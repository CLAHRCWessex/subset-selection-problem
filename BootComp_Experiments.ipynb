{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of BootComp against OBCA-m on single objective problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reruns some of the analysis published with OBCA-m, using common random numbers (CRN) and the BootComp algorithm.\n",
    "\n",
    "All problems are single objective with no chance constraints.\n",
    "\n",
    "* The first problem has 10 system designs with a constant variance.  That task is to return the top 3 (largest) systems.\n",
    "\n",
    "* The second problem is taken from the Law inventory problem, but is adapted to operate with common random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all problems used in the comparison do not have chance constraints then only the `quality_bootstrap()` function is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bootcomp.bootstrap import quality_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for creating the data used in the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def bootstrap(data, boots=1000):\n",
    "    \"\"\"\n",
    "    Returns a numpy array containing the bootstrap resamples\n",
    "    Useful for creating a large number of experimental datasets \n",
    "    for testing R&S routines\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data -- numpy.ndarray of systems to boostrap\n",
    "    boots -- integer number of bootstraps (default = 1000)\n",
    "    \"\"\"\n",
    "    experiments = boots\n",
    "    designs = 10\n",
    "    samples = data.shape[1]\n",
    "\n",
    "    datasets = np.zeros((experiments, designs, samples))\n",
    "     \n",
    "    for exp in range(experiments):\n",
    "        \n",
    "        for design in range(designs):\n",
    "\n",
    "            for i in range(samples):\n",
    "\n",
    "                datasets[exp][design][i] = data[design][round(np.random.uniform(0, samples)-1)]\n",
    "      \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def crn_bootstrap(data, boots=1000):\n",
    "    \"\"\"\n",
    "    Returns a numpy array containing the bootstrap resamples\n",
    "    Useful for creating a large number of experimental datasets \n",
    "    for testing R&S routines.  This function assumes common\n",
    "    random numbers have been used to create the original data.\n",
    "    \n",
    "    Keyword arguments\n",
    "    data -- numpy.ndarray of systems to boostrap\n",
    "    boots -- integer number of bootstraps (default = 1000)\n",
    "    \"\"\"\n",
    "\n",
    "    experiments = boots\n",
    "    designs = data.shape[0]\n",
    "    samples = data.shape[1]\n",
    "    \n",
    "    datasets = np.zeros((experiments, designs, samples))\n",
    "     \n",
    "    for exp in range(experiments):\n",
    "        \n",
    "         for i in range(samples):\n",
    "\n",
    "                row = data.T[np.random.choice(data.shape[0])]\n",
    "                \n",
    "                for design in range(designs):\n",
    "                    datasets[exp][design][i] = row[design]  \n",
    "      \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs_np(data, boots=1000):\n",
    "    \"\"\"\n",
    "    Alternative bootstrap routine that works exclusively with a numpy \n",
    "    array.  Seems to offer limited performance improvement!?\n",
    "    What am I doing in the standard Python code that makes it so efficient?\n",
    "    Expense operations here are: round, random.uniform - but only to a limited\n",
    "    extent!\n",
    "    \n",
    "    Returns a numpy array containing the bootstrap resamples\n",
    "    @data = numpy array of systems to boostrap\n",
    "    @boots = number of bootstrap (default = 1000)\n",
    "    \"\"\"\n",
    "    to_return = np.empty([boots, data.shape[0]])\n",
    "    \n",
    "    sys_index =0\n",
    "    total=0\n",
    "        \n",
    "    for system in data:\n",
    "        \n",
    "        for b in range(boots):\n",
    "        \n",
    "            for i in range(system.shape[0]):\n",
    "                \n",
    "                x = (np.random.uniform(0, system.shape[0]-1))\n",
    "                \n",
    "                total += system[round(x)]\n",
    "\n",
    "            to_return[b, sys_index] = total / system.shape[0]\n",
    "            total= 0\n",
    "        sys_index += 1\n",
    "            \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following code to create independent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments_independent_samples(ifile_name, boots=1000):\n",
    "    data = np.genfromtxt(ifile_name, delimiter=\",\", skip_footer=0).transpose()\n",
    "    experiments = bootstrap(data, boots=boots)\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following code to create CRN data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments_dependent_samples(ifile_name, boots=1000):\n",
    "    data = np.genfromtxt(ifile_name, delimiter=\",\", skip_footer=0).transpose()\n",
    "    experiments = crn_bootstrap(data, boots=boots)\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated version of BootComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used in practice BootComp is run in two stages.\n",
    "\n",
    "After an $n_0$ initial replications the user can then decide how strict to be with the quality bootstrap. This will affect the number of system designs carried For example, if user required designs to be within 5% of the best mean 95% of the time then this might only carry over m-1 designs. In these circumstances the user might be less conservative and allow designs to be within 10-20% of best.  \n",
    "\n",
    "The automated BootComp routines attempts to mimic this decision making process.  It is given a range of tolerances to consider and returns the most conservative estimate that returns at least m designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_experiment(model, reps, systems):\n",
    "    return model[:,:reps][systems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(selected_top_m, true_top_m):\n",
    "    \"\"\"Returns boolean value:\n",
    "    True = correct selection of top m\n",
    "    False = incorrect selection (one or more of selected top m is incorrect)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    selected_top_m --   numpy.array containing the indexes of \n",
    "                        the top m means selected by the algorithm\n",
    "                        \n",
    "    true_top_m --       numpy.array containing the indexes of \n",
    "                        the true top m means\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.array_equal(np.sort(selected_top_m), true_top_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_budgets(max_t, min_t, increment_t):\n",
    "    #incremental budgets 200, 400, .... T\n",
    "    budgets = [i for i in range(min_t, max_t + increment_t, increment_t)]\n",
    "    return budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_stage(model, design_indexes, reps, x, y, boots):\n",
    "    \n",
    "    output_data = simulate_experiment(model=model, \n",
    "                               reps=reps, \n",
    "                               systems=design_indexes)\n",
    "    \n",
    "    best_design_index_sub = output_data.mean(axis=1).argmax()\n",
    "        \n",
    "    best_design_index = design_indexes[best_design_index_sub]\n",
    "        \n",
    "    df_output = pd.DataFrame(output_data).T\n",
    "    df_output.columns = design_indexes \n",
    "    \n",
    "    results = quality_bootstrap(df_output, \n",
    "                                design_indexes, \n",
    "                                best_design_index, \n",
    "                                x, y, boots)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootcomp(model, budget, m, n_0, boots, x1, y1, x2, y2):\n",
    "\n",
    "    #stage 1\n",
    "    #simulate n reps from all system designs\n",
    "    k = model.shape[0]\n",
    "    design_indexes = [i for i in range(k)]\n",
    "\n",
    "    stage_one_results = simulate_stage(model, design_indexes,\n",
    "                                      reps=n_0, x=x1, y=y1, boots=boots)\n",
    "    \n",
    "    #stage 2\n",
    "    #equal allocation of remaining budget\n",
    "    stage_two_reps = int((budget - (n_0 * k))/len(stage_one_results)) + n_0\n",
    "       \n",
    "    design_indexes = (stage_one_results).tolist()\n",
    "        \n",
    "    stage_two_results = simulate_stage(model, design_indexes,\n",
    "                                       reps=stage_two_reps, \n",
    "                                       x=x2, y=y1, boots=boots)\n",
    "\n",
    "    return stage_two_results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_experiment(experiments, budgets, m, n_0, true_top_m, \n",
    "                         x1, y1, x2, y2, nboots=1000):\n",
    "    \"\"\"\n",
    "    Conduct a user set number of numerical experiments on the algorithm\n",
    "    for different computational budgets\n",
    "    \n",
    "    Returns:\n",
    "    1. numpy.ndarray containing P{cs} for each budget\n",
    "        \n",
    "    Keyword arguments:\n",
    "    experiments -- numpy.ndarray[experiments][designs][replication]\n",
    "    budgets -- python list containing budgets\n",
    "    model_file -- string path to model \n",
    "    \n",
    "    \"\"\"\n",
    "    n_experiments = experiments.shape[0]\n",
    "    k = experiments.shape[1]  \n",
    "    \n",
    "    correct_selections = np.zeros((n_experiments, len(budgets)))\n",
    "   \n",
    "    for exp in range(n_experiments):\n",
    "\n",
    "        for t in range(len(budgets)):\n",
    "\n",
    "            selected_top_m = bootcomp(budget=budgets[t],\n",
    "                                      model=experiments[exp],\n",
    "                                      m=m, \n",
    "                                      n_0=n_0, \n",
    "                                      boots=nboots, x1=x1, y1=y1, \n",
    "                                      x2=x2, y2=y2)\n",
    "                    \n",
    "            correct_selections[exp][t] = cs(selected_top_m[-m:], \n",
    "                                            true_top_m)\n",
    "                        \n",
    "    return correct_selections\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Top 3 systems from 10\n",
    "\n",
    "In this example we simulate 10,000 experiments of 10 competing system designs.  Each design has equal variance.  BootComp must return the 3 designs with the largest mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_1():\n",
    "    T = 3000\n",
    "    increment_t = 100\n",
    "    min_budget = 300\n",
    "    n_0 = 20\n",
    "    n_experiments = 10000\n",
    "    x1 = 0.3\n",
    "    y1 = 0.8\n",
    "    x2 = 0.3\n",
    "    y2 = 0.95\n",
    "    boots=1000\n",
    "    m = 3\n",
    "\n",
    "    #specific to this implementation\n",
    "    ifile_name = 'data/EG1a_CRN.csv'\n",
    "    reps_available = 10000\n",
    "\n",
    "    #info for correct selection\n",
    "    true_top_m = np.array([7, 8, 9])\n",
    "    true_means = np.arange(1, 11)\n",
    "\n",
    "    #incremental budgets 200, 400, .... T\n",
    "    budgets = get_budgets(T, min_budget, increment_t)\n",
    "    \n",
    "    #generate experimental dataset\n",
    "    experiments = experiments_dependent_samples(ifile_name, \n",
    "                                                boots=n_experiments)\n",
    "    \n",
    "    #run numerical experiment\n",
    "    css = numerical_experiment(experiments, \n",
    "                               budgets, \n",
    "                               m,\n",
    "                               n_0,\n",
    "                               true_top_m, \n",
    "                               x1, y1, x2, y2, boots)\n",
    "    return css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1    2    3    4    5    6    7    8    9  ...    18   19   20   21  \\\n",
      "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
      "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
      "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
      "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
      "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
      "\n",
      "    22   23   24   25   26   27  \n",
      "0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "1  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "2  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "3  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "4  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "CPU times: user 7.26 s, sys: 1.89 ms, total: 7.26 s\n",
      "Wall time: 7.24 s\n"
     ]
    }
   ],
   "source": [
    "css = experiment_1()\n",
    "#print(pd.DataFrame(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
